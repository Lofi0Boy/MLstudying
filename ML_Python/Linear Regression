{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyN/KmFTXNFOdR9JPmwfp1oG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["극소의 개념을 1e-4로 대체. 공학적 허용인듯\n","\n"],"metadata":{"id":"kYzmTVhklS7e"}},{"cell_type":"code","source":["import numpy as np\n","\n","def numerical_derivative(f,x):\n","\n","  delta_x = 1e-4\n","\n","  return((f(x+delta_x)-f(x-delta_x))/(2*delta_x))\n","\n","def f1(x):\n","  return x**2\n","\n","result1 = numerical_derivative(f1,3)\n","\n","print(\"result1 : \",result1)\n","\n","def f2(x):\n","  result = 3*x*np.exp(x)\n","  return result\n","\n","result2 = numerical_derivative(f2,0)\n","print(\"result2 : \",result2)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_hMP26I3lSBW","executionInfo":{"status":"ok","timestamp":1705397519412,"user_tz":-540,"elapsed":5,"user":{"displayName":"이상","userId":"14296519550561623483"}},"outputId":"6bfba653-7203-4400-d88e-101fa5e70bee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["result1 :  6.000000000012662\n","result2 :  3.000000015\n"]}]},{"cell_type":"markdown","source":["numerical derivative of multi-variable function"],"metadata":{"id":"X6IisiREnQAL"}},{"cell_type":"code","source":["import numpy as np\n","\n","def numerical_derivative(f,x): #f는 다변수 함수, x는 원하는 지점의 벡터 or 행렬\n","\n","\n","  delta = 1e-4\n","  grad = np.zeros_like(x) #x벡터크기 0벡터 생성\n","  # print('debug:input x :',x)\n","  # print('debug:initial grad :',grad)\n","\n","  it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite']) #multi_index라는 변수에 인덱스저장\n","\n","  while not it.finished:\n","    idx = it.multi_index #it(iterator의 현재 index)\n","    # print('debud:idx',idx)\n","    tmp = x[idx] #기존값 보존\n","    # print('debug: tmp :',tmp)\n","    x[idx] = float(tmp + delta)\n","    fx1 = f(x)\n","    # print('debug: fx1:',fx1)\n","    x[idx] = tmp - delta\n","    # print('debug:tmp,delta, x[idx]:',tmp,delta,x[idx])\n","    # print('debug:tmp-delta',tmp-delta)\n","    fx2 = f(x)\n","    # print('debug: fx2:',fx2)\n","\n","    grad[idx] = (fx1-fx2)/(delta*2)\n","    x[idx] = tmp #다른변수들 변화율 구할때 오차 없기 위해 기존값 복원\n","\n","    it.iternext()#직접 넘겨줘야함.\n","\n","  return grad\n","\n","\n","def f1(x):\n","  return x[0]**2\n","\n","\n","# grad1 = numerical_derivative(f1,[6,0]) array와 np array의 차이점?\n","# grad1 = numerical_derivative(f1,np.array([6,0])) np array만들때 정수로 값을 넣어버리면 type이 integer로 고정되어서 이후 계산에서도 소수점 버림 현상 발생\n","grad1 = numerical_derivative(f1,np.array([6.0,0.0]))\n","\n","print(grad1)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LsV8Uq9qnfgx","executionInfo":{"status":"ok","timestamp":1705996523760,"user_tz":-540,"elapsed":354,"user":{"displayName":"이상","userId":"14296519550561623483"}},"outputId":"9ac396e5-b5f5-4f19-f882-6c8cc6741b3a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[12.  0.]\n"]}]},{"cell_type":"markdown","source":["지도학습 vs 비지도학습\n","Supervised Learning vs Unsupervised Learning\n","\n","Supervised\n","- Regression\n","주어진 Income,Outcome으로 선형적인 관계를 추측해 새로운 Income에 대한 Outcome 예측\n","- Clustering\n","주어진 군집을 활용해 새로운 Income의 Group예측\n","\n","Unsupervised\n","- Clustering\n","주어진 data의 특성을 알아서 분류해 Clustering"],"metadata":{"id":"lqi-Zd2Wrpjy"}},{"cell_type":"markdown","source":["Supervised Learning - Linear Regression Model\n","\n","Input Output 데이터를 활용해\n","\n","y = Wx + b의 관계를 찾아냄\n","\n","W : weight\n","b : bias\n","\n","error : t(정답)-y\n","\n","loss function (cost function)\n","\n","sigma(t-y)^2 / n -> 오차값이 클수록 손실함수값이 극대화 되므로 학습에 유리함.\n","\n"],"metadata":{"id":"r4YlT4ETrpmI"}},{"cell_type":"markdown","source":["Linear Regression - Gradient Decent Algorithm\n","\n","y = Wx + b\n","\n","b를 고정시킨 상태로 W를 변화시키면서 loss function 값이 최소인 W를 찾는다."],"metadata":{"id":"QfR65stCwSPS"}},{"cell_type":"markdown","source":["**Numerical Derivative - for 1 dimension**"],"metadata":{"id":"QRJh3nrhwSR2"}},{"cell_type":"code","source":["import numpy as np\n","def linear_function(x):\n","  w = np.array([3,2,1])\n","  b = 7\n","  #if(x.size<w.size) 이런 처리를 해줘야하는 상황이 있을수도 있겠네.\n","  return np.dot(w,x)+b\n","\n","def derivative(f,x):\n","\n","  grad = np.zeros_like(x)\n","  #zero => 0.0이라 실수타입\n","  #numpy의 array는 데이터 타입 고정, C의 array처럼 작동한다. 사칙연산도 원소별로 작동\n","\n","  it = np.nditer(x,flags=['multi_index'])\n","  #it는 해당 array의 현재 좌표를 찍어주는데, multi_index로 플래그 설정하면 차원수에 따라 자동적으로 (0,1),혹은 (0,0,1) 이런식으로 알아서 인덱스 설정해줌.\n","  #고차원 인풋이 발생하는 머신러닝에서는 이런 방식을 쓰는게 코드효율성 굿\n","\n","  delta = 1e-4\n","\n","  while not it.finished:\n","    i = it.multi_index\n","    ordinary = x[i]\n","\n","    x[i] = ordinary+delta\n","    fx1 = f(x)\n","\n","    x[i] = ordinary-delta\n","    fx2 = f(x)\n","\n","    x[i]=ordinary\n","    derivation = (fx1-fx2)/(2*delta)\n","    grad[i]=derivation\n","    it.iternext()\n","\n","  return grad\n","\n","x = np.array([1.0,2.0,3.0])\n","print(derivative(linear_function,x))\n","\n","#input data가 1차원인 상황. 2차원으로 가면 어떻게 될라나,"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SQXtN31Qyfii","executionInfo":{"status":"ok","timestamp":1706024040850,"user_tz":-540,"elapsed":490,"user":{"displayName":"이상","userId":"14296519550561623483"}},"outputId":"d47f3e23-68ed-4db4-a40a-c4896e2fb136"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[3. 2. 1.]\n"]}]},{"cell_type":"markdown","source":["**Linear Regression(Linear function인 경우에나 가능하겠지)**\n","\n","1. lost function\n","\n","오차값제곱을 데이터 개수만큼 나눔.\n","\n","2. Gradient Decent Algorithm\n","\n","dE(W)/dw 가 0에 가까워지록 조금씩 이동\n","(E함수가 w에 대한 2차식일것임을 가정. 데이터가 Linear하다면 맞는 가정.)\n","\n","조금씩 : α*dE/dw\n","\n"],"metadata":{"id":"sfRhL0MW9drv"}},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lHYec7HnCVwg","executionInfo":{"status":"ok","timestamp":1706511921498,"user_tz":-540,"elapsed":2375,"user":{"displayName":"이상","userId":"14296519550561623483"}},"outputId":"744117a3-d2cf-4652-dc6b-8a11dbc52764"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["\n","import numpy as np\n","\n","\n","def derivative(f,x):\n","  delta = 1e-4\n","\n","  it = np.nditer(x,flags=['multi_index'])\n","\n","  grad = np.zeros_like(x)\n","\n","  while not it.finished:\n","    i = it.multi_index\n","\n","    stored_val = x[i]\n","    x[i] = stored_val+delta\n","    fx1 = f(x)\n","\n","    x[i] = stored_val-delta\n","    fx2 = f(x)\n","\n","    x[i] = stored_val\n","    grad[i] = (fx1-fx2)/(delta*2)\n","    it.iternext()\n","\n","  return grad\n","\n","def loss():\n","  predicted = np.dot(x,w)+b\n","  err_square=((predicted-t)**2)\n","  return np.sum(err_square)/len(x)\n","\n","def grad_decent_algorithm():\n","  global w,b\n","  step = 10001\n","\n","  f = lambda x : loss()\n","\n","  learning_rate = 1e-5\n","\n","  for i in range(step):\n","    if i%1000 == 0 :\n","      print(\"Progress in \",int((i/step)*100),\"%\")\n","      print(\"Current W :\",w)\n","      print(\"Current b :\",b)\n","    w -= learning_rate*derivative(f,w)\n","    b -= learning_rate*derivative(f,b)\n","\n","def predict(x):\n","    y = np.dot(x,w) + b\n","\n","    return y\n","loaded_data = np.loadtxt('/content/drive/MyDrive/data-01-test-score.csv',delimiter=',',dtype = np.float32)\n","\n","x = loaded_data[:,0:-1]\n","t = loaded_data[:,-1:]\n","w=np.random.rand(3,1)\n","b=np.random.rand(1)\n","\n","grad_decent_algorithm()\n","\n","test_data = np.array([100,98,81])\n","predict(test_data)\n","\n"],"metadata":{"id":"Qkb3HDy89xk5","executionInfo":{"status":"ok","timestamp":1706513008588,"user_tz":-540,"elapsed":1667,"user":{"displayName":"이상","userId":"14296519550561623483"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2de2cbfd-d3a6-4ea5-fb18-8ff3ad915d50"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Progress in  0 %\n","Current W : [[0.78757058]\n"," [0.2223143 ]\n"," [0.21061482]]\n","Current b : [0.52571621]\n","Progress in  9 %\n","Current W : [[0.8961919 ]\n"," [0.4538832 ]\n"," [0.67044535]]\n","Current b : [0.52747857]\n","Progress in  19 %\n","Current W : [[0.77505596]\n"," [0.44223233]\n"," [0.79956633]]\n","Current b : [0.52677169]\n","Progress in  29 %\n","Current W : [[0.68131221]\n"," [0.44329226]\n"," [0.88964878]]\n","Current b : [0.52573762]\n","Progress in  39 %\n","Current W : [[0.60868569]\n"," [0.45061533]\n"," [0.95309064]]\n","Current b : [0.52447371]\n","Progress in  49 %\n","Current W : [[0.55236723]\n"," [0.46048501]\n"," [0.99819673]]\n","Current b : [0.52304687]\n","Progress in  59 %\n","Current W : [[0.50866131]\n"," [0.47084343]\n"," [1.03056902]]\n","Current b : [0.52150349]\n","Progress in  69 %\n","Current W : [[0.47472167]\n"," [0.48062425]\n"," [1.05401527]]\n","Current b : [0.51987604]\n","Progress in  79 %\n","Current W : [[0.44835208]\n"," [0.48934088]\n"," [1.07114519]]\n","Current b : [0.51818746]\n","Progress in  89 %\n","Current W : [[0.42785513]\n"," [0.49683478]\n"," [1.08376314]]\n","Current b : [0.51645412]\n","Progress in  99 %\n","Current W : [[0.41191718]\n"," [0.50312383]\n"," [1.09312814]]\n","Current b : [0.5146878]\n"]},{"output_type":"execute_result","data":{"text/plain":["array([179.55572988])"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":[],"metadata":{"id":"mEX6uoPx_cn7"}},{"cell_type":"code","source":[],"metadata":{"id":"mepD08TXLvfM"},"execution_count":null,"outputs":[]}]}